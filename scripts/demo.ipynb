{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "from hart.data import disp\n",
    "from hart.data.kitti.tools import get_data\n",
    "from hart.model import util\n",
    "from hart.model.attention_ops import FixedStdAttention\n",
    "from hart.model.eval_tools import log_norm, log_ratios, log_values, make_expr_logger\n",
    "from hart.model.tracker import HierarchicalAttentiveRecurrentTracker as HART\n",
    "from hart.model.nn import AlexNetModel, IsTrainingLayer\n",
    "from hart.train_tools import TrainSchedule, minimize_clipped\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_imgs(img_dir):\n",
    "    img_paths = sorted(os.listdir(img_dir))\n",
    "    imgs = np.empty([len(img_paths), 1] + list(img_size), dtype=np.float32)\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        img_path= os.path.join(img_dir, img_path)\n",
    "        imgs[i, 0] = imresize(imread(img_path), img_size[:2])\n",
    "        \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alexnet_dir = 'checkpoints'\n",
    "img_dir = 'imgs'\n",
    "# checkpoint_path = 'checkpoints/kitti/pretrained/2017_07_06_16.41/model.ckpt-142320'\n",
    "checkpoint_path = 'checkpoints/kitti/pretrained/model.ckpt-347346'\n",
    "\n",
    "batch_size = 1\n",
    "img_size = 187, 621, 3\n",
    "crop_size = 56, 56, 3\n",
    "\n",
    "rnn_units = 100\n",
    "norm = 'batch'\n",
    "keep_prob = .75\n",
    "\n",
    "img_size, crop_size = [np.asarray(i) for i in (img_size, crop_size)]\n",
    "keys = ['img', 'bbox', 'presence']\n",
    "\n",
    "bbox_shape = (1, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "util.set_random_seed(0)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, batch_size] + list(img_size), name='image')\n",
    "y0 = tf.placeholder(tf.float32, bbox_shape, name='bbox')\n",
    "p0 = tf.ones(y0.get_shape()[:-1], dtype=tf.uint8, name='presence')\n",
    "\n",
    "is_training = IsTrainingLayer()\n",
    "builder = AlexNetModel(alexnet_dir, layer='conv3', n_out_feature_maps=5, upsample=False, normlayer=norm,\n",
    "                       keep_prob=keep_prob, is_training=is_training)\n",
    "\n",
    "model = HART(x, y0, p0, batch_size, crop_size, builder, rnn_units,\n",
    "             bbox_gain=[-4.78, -1.8, -3., -1.8],\n",
    "             zoneout_prob=(.05, .05),\n",
    "             normalize_glimpse=True,\n",
    "             attention_module=FixedStdAttention,\n",
    "             debug=True,\n",
    "             transform_init_features=True,\n",
    "             transform_init_state=True,\n",
    "             dfn_readout=True,\n",
    "             feature_shape=(14, 14),\n",
    "             is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, checkpoint_path)\n",
    "model.test_mode(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = load_imgs(img_dir)\n",
    "bbox = [88, 250, 18, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {x: imgs, y0: np.reshape(bbox, bbox_shape)}\n",
    "tensors = [model.pred_bbox, model.att_pred_bbox, model.glimpse, model.obj_mask]\n",
    "pred_bbox, pred_att, glimpse, obj_mask = sess.run(tensors, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = imgs.shape[0]\n",
    "fig, axes = plt.subplots(n, 3, figsize=(20, 2*n))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax[0].imshow(imgs[i].squeeze() / 255.)\n",
    "    ax[1].imshow(glimpse[i].squeeze())\n",
    "    ax[2].imshow(obj_mask[i].squeeze(), cmap='gray', vmin=0., vmax=1.)\n",
    "    disp.rect(pred_bbox[i].squeeze(), 'b', ax=ax[0])\n",
    "    disp.rect(pred_att[i].squeeze(), 'g', ax=ax[0])\n",
    "    for a in ax:\n",
    "        a.xaxis.set_visible(False)\n",
    "        a.yaxis.set_visible(False)\n",
    "        \n",
    "axes[0, 0].plot([], c='g', label='att')\n",
    "axes[0, 0].plot([], c='b', label='pred')\n",
    "axes[0, 0].legend(loc='center right')\n",
    "axes[0, 0].set_xlim([0, img_size[1]])\n",
    "axes[0, 0].set_ylim([img_size[0], 0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}