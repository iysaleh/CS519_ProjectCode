{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "from hart.data import disp\n",
    "from hart.data.kitti.tools import get_data\n",
    "from hart.model import util\n",
    "from hart.model.attention_ops import FixedStdAttention,RATMAttention\n",
    "from hart.model.eval_tools import log_norm, log_ratios, log_values, make_expr_logger\n",
    "from hart.model.tracker import HierarchicalAttentiveRecurrentTracker as HART\n",
    "from hart.model.nn import AlexNetModel, IsTrainingLayer\n",
    "from hart.train_tools import TrainSchedule, minimize_clipped\n",
    "\n",
    "import glob\n",
    "import moviepy.editor as mpy\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(img_dir):\n",
    "    img_paths = sorted(os.listdir(img_dir))\n",
    "    imgs = np.empty([len(img_paths), 1] + list(img_size), dtype=np.float32)\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        img_path= os.path.join(img_dir, img_path)\n",
    "        imgs[i, 0] = imresize(imread(img_path), img_size[:2])\n",
    "        \n",
    "    return imgs\n",
    "def write_imgs_glimpses_objmasks_to_file(imgs,glimpse,obj_mask,pred_bbox,pred_att,base_path):\n",
    "    n_images = imgs.shape[0]\n",
    "    for i in xrange(n_images):\n",
    "        #cv2 rectangle parameters here are the image, the top left coordinate, bottom right coordinate, color, and line thickness.\n",
    "        y1_bbox = pred_bbox[i].squeeze()[0]\n",
    "        x1_bbox = pred_bbox[i].squeeze()[1]\n",
    "        y2_bbox = y1_bbox + pred_bbox[i].squeeze()[2]\n",
    "        x2_bbox = x1_bbox + pred_bbox[i].squeeze()[3]\n",
    "        \n",
    "        y1_att = pred_att[i].squeeze()[0]\n",
    "        x1_att = pred_att[i].squeeze()[1]\n",
    "        y2_att = y1_att + pred_att[i].squeeze()[2]\n",
    "        x2_att = x1_att + pred_att[i].squeeze()[3]\n",
    "        \n",
    "        #Blue will be prediction BBOX\n",
    "        cv2.rectangle(imgs[i].squeeze(),(x1_bbox,y1_bbox),(x2_bbox,y2_bbox),(0,0,255),1)\n",
    "        #Red will be attention BBOX\n",
    "        cv2.rectangle(imgs[i].squeeze(),(x1_att,y1_att),(x2_att,y2_att),(255,0,0),1)\n",
    "\n",
    "        plt.imsave(base_path+\"_img_\"+str(i)+\".png\",imgs[i].squeeze() / 255.)\n",
    "        plt.imsave(base_path+\"_glimpse_\"+str(i)+\".png\",glimpse[i].squeeze())\n",
    "        plt.imsave(base_path+\"_objMask_\"+str(i)+\".png\",obj_mask[i].squeeze(), cmap='gray', vmin=0., vmax=1.)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_dir = 'checkpoints'\n",
    "img_dir = 'data/kitti_tracking/small_test/0016'\n",
    "img_dir = 'data/kitti_tracking/small/0015'\n",
    "#img_dir = 'data/my_experiments/frames_small/ApplesRollingAmongstApples'\n",
    "img_dir = 'data/my_experiments/frames_small/CarOnRoad'\n",
    "# checkpoint_path = 'checkpoints/kitti/pretrained/2017_07_06_16.41/model.ckpt-142320'\n",
    "checkpoint_path = 'checkpoints/kitti/pretrained/model.ckpt-347346'\n",
    "\n",
    "batch_size = 1\n",
    "img_size = 187, 621, 3\n",
    "crop_size = 56, 56, 3\n",
    "\n",
    "rnn_units = 100\n",
    "norm = 'batch'\n",
    "keep_prob = .75\n",
    "\n",
    "img_size, crop_size = [np.asarray(i) for i in (img_size, crop_size)]\n",
    "keys = ['img', 'bbox', 'presence']\n",
    "\n",
    "bbox_shape = (1, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "util.set_random_seed(0)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, batch_size] + list(img_size), name='image')\n",
    "y0 = tf.placeholder(tf.float32, bbox_shape, name='bbox')\n",
    "p0 = tf.ones(y0.get_shape()[:-1], dtype=tf.uint8, name='presence')\n",
    "\n",
    "is_training = IsTrainingLayer()\n",
    "builder = AlexNetModel(alexnet_dir, layer='conv3', n_out_feature_maps=5, upsample=False, normlayer=norm,\n",
    "                       keep_prob=keep_prob, is_training=is_training)\n",
    "\n",
    "model = HART(x, y0, p0, batch_size, crop_size, builder, rnn_units,\n",
    "             bbox_gain=[-4.78, -1.8, -3., -1.8],\n",
    "             zoneout_prob=(.05, .05),\n",
    "             normalize_glimpse=True,\n",
    "             attention_module=FixedStdAttention,\n",
    "             debug=True,\n",
    "             transform_init_features=True,\n",
    "             transform_init_state=True,\n",
    "             dfn_readout=True,\n",
    "             feature_shape=(14, 14),\n",
    "             is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/kitti/pretrained/model.ckpt-347346\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, checkpoint_path)\n",
    "model.test_mode(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_imgs(img_dir)\n",
    "##bbox = y_origin,x_origin,y_add,x_add\n",
    "#bbox = [88, 250, 18, 25]\n",
    "x_start = 396\n",
    "y_start = 68\n",
    "x_end = 434\n",
    "y_end = 90\n",
    "bbox = [y_start,x_start,y_end-y_start,x_end-x_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x: imgs, y0: np.reshape(bbox, bbox_shape)}\n",
    "tensors = [model.pred_bbox, model.att_pred_bbox, model.glimpse, model.obj_mask]\n",
    "pred_bbox, pred_att, glimpse, obj_mask = sess.run(tensors, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nn = imgs.shape[0]\\nfig, axes = plt.subplots(n, 3, figsize=(20, 2*n))\\nfor i, ax in enumerate(axes):\\n    ax[0].imshow(imgs[i].squeeze() / 255.)\\n    ax[1].imshow(glimpse[i].squeeze())\\n    ax[2].imshow(obj_mask[i].squeeze(), cmap='gray', vmin=0., vmax=1.)\\n    disp.rect(pred_bbox[i].squeeze(), 'b', ax=ax[0])\\n    disp.rect(pred_att[i].squeeze(), 'g', ax=ax[0])\\n    for a in ax:\\n        a.xaxis.set_visible(False)\\n        a.yaxis.set_visible(False)\\n        \\naxes[0, 0].plot([], c='g', label='att')\\naxes[0, 0].plot([], c='b', label='pred')\\naxes[0, 0].legend(loc='center right')\\naxes[0, 0].set_xlim([0, img_size[1]])\\naxes[0, 0].set_ylim([img_size[0], 0])\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "n = imgs.shape[0]\n",
    "fig, axes = plt.subplots(n, 3, figsize=(20, 2*n))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax[0].imshow(imgs[i].squeeze() / 255.)\n",
    "    ax[1].imshow(glimpse[i].squeeze())\n",
    "    ax[2].imshow(obj_mask[i].squeeze(), cmap='gray', vmin=0., vmax=1.)\n",
    "    disp.rect(pred_bbox[i].squeeze(), 'b', ax=ax[0])\n",
    "    disp.rect(pred_att[i].squeeze(), 'g', ax=ax[0])\n",
    "    for a in ax:\n",
    "        a.xaxis.set_visible(False)\n",
    "        a.yaxis.set_visible(False)\n",
    "        \n",
    "axes[0, 0].plot([], c='g', label='att')\n",
    "axes[0, 0].plot([], c='b', label='pred')\n",
    "axes[0, 0].legend(loc='center right')\n",
    "axes[0, 0].set_xlim([0, img_size[1]])\n",
    "axes[0, 0].set_ylim([img_size[0], 0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"CarOnRoad\"\n",
    "path = 'results/%s'%filename\n",
    "try:\n",
    "    os.makedirs(path+'/gifs')\n",
    "except:\n",
    "    pass\n",
    "write_imgs_glimpses_objmasks_to_file(imgs,glimpse,obj_mask,pred_bbox,pred_att,'%s/%s'%(path,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  67.79806519  395.47900391   22.78027916   38.12802505]]]\n"
     ]
    }
   ],
   "source": [
    "print(pred_att[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MoviePy] Building file results/CarOnRoad/gifs/CarOnRoad_images.gif with imageio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [00:47<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MoviePy] Building file results/CarOnRoad/gifs/CarOnRoad_glimpses.gif with imageio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 450/450 [00:03<00:00, 121.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MoviePy] Building file results/CarOnRoad/gifs/CarOnRoad_objMasks.gif with imageio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 450/450 [00:00<00:00, 835.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MoviePy] Building file results/CarOnRoad/gifs/CarOnRoadoriginal.gif with imageio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 450/450 [00:46<00:00,  9.63it/s]\n"
     ]
    }
   ],
   "source": [
    "gif_imgs_name = path+'/gifs/'+filename+'_images'\n",
    "gif_glimpses_name = path+'/gifs/'+filename+'_glimpses'\n",
    "gif_objMasks_name = path+'/gifs/'+filename+'_objMasks'\n",
    "gif_orig_name = path+'/gifs/'+filename+'original'\n",
    "\n",
    "file_list_imgs = glob.glob('%s/*_img_*.png'%path) # Get all the pngs in the current directory\n",
    "file_list_glimpses = glob.glob('%s/*_glimpse_*.png'%path) # Get all the pngs in the current directory\n",
    "file_list_objMasks = glob.glob('%s/*_objMask_*.png'%path) # Get all the pngs in the current directory\n",
    "file_list_original =  glob.glob('%s/*.png'%img_dir) # Get all the pngs in the current directory\n",
    "\n",
    "#fps = 4\n",
    "fps = 23\n",
    "\n",
    "list.sort(file_list_imgs, key=lambda x: int(x.split('_')[-1].split('.png')[0])) # Sort the images by #, this may need to be tweaked for your use case\n",
    "list.sort(file_list_glimpses, key=lambda x: int(x.split('_')[-1].split('.png')[0])) # Sort the images by #, this may need to be tweaked for your use case\n",
    "list.sort(file_list_objMasks, key=lambda x: int(x.split('_')[-1].split('.png')[0])) # Sort the images by #, this may need to be tweaked for your use case\n",
    "#For KITTI\n",
    "#list.sort(file_list_original, key=lambda x: int(x.split('/')[-1].split('.png')[0])) # Sort the images by #, this may need to be tweaked for your use case\n",
    "#For My Data\n",
    "list.sort(file_list_original, key=lambda x: int(x.split('-')[-1].split('.png')[0])) # Sort the images by #, this may need to be tweaked for your use case\n",
    "\n",
    "clip_imgs = mpy.ImageSequenceClip(file_list_imgs, fps=fps)\n",
    "clip_glimpses = mpy.ImageSequenceClip(file_list_glimpses, fps=fps)\n",
    "clip_objMasks = mpy.ImageSequenceClip(file_list_objMasks, fps=fps)\n",
    "clip_original = mpy.ImageSequenceClip(file_list_original, fps=fps)\n",
    "\n",
    "clip_imgs.write_gif('{}.gif'.format(gif_imgs_name), fps=fps)\n",
    "clip_glimpses.write_gif('{}.gif'.format(gif_glimpses_name), fps=fps)\n",
    "clip_objMasks.write_gif('{}.gif'.format(gif_objMasks_name), fps=fps)\n",
    "clip_original.write_gif('{}.gif'.format(gif_orig_name), fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
